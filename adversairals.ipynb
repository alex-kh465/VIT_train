{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the trained ViT model\n",
    "model = timm.create_model(\"vit_base_patch16_224\", pretrained=False, num_classes=10)\n",
    "model.load_state_dict(torch.load(\"vit_cifar10.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Data Transformations (same as before)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  \n",
    "])\n",
    "\n",
    "# Load CIFAR-10 test dataset\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def fgsm_attack(image, epsilon, gradient):\n",
    "    \"\"\"\n",
    "    Generates an FGSM adversarial example by perturbing the image along the sign of the gradient.\n",
    "    \"\"\"\n",
    "    perturbation = epsilon * gradient.sign()\n",
    "    adv_image = image + perturbation\n",
    "    adv_image = torch.clamp(adv_image, -1, 1)  # Keep pixel values in range\n",
    "    return adv_image\n",
    "\n",
    "def test_fgsm(model, test_loader, epsilon):\n",
    "    \"\"\"\n",
    "    Evaluates the model on adversarial examples generated using FGSM.\n",
    "    \"\"\"\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        images.requires_grad = True\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Compute gradients\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        gradient = images.grad.data\n",
    "\n",
    "        # Generate adversarial example\n",
    "        adv_images = fgsm_attack(images, epsilon, gradient)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        adv_outputs = model(adv_images)\n",
    "        _, adv_pred = torch.max(adv_outputs, 1)\n",
    "\n",
    "        # Compare predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (adv_pred == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"FGSM Attack (ε={epsilon}) - Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Run FGSM Attack\n",
    "epsilons = [0.01, 0.1, 0.2]  # Test different strengths\n",
    "for eps in epsilons:\n",
    "    test_fgsm(model, test_loader, eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def pgd_attack(image, label, model, epsilon, alpha, iters):\n",
    "    \"\"\"\n",
    "    Generates a PGD adversarial example by iteratively perturbing the image.\n",
    "    \"\"\"\n",
    "    perturbed_image = image.clone().detach().to(device)\n",
    "    perturbed_image.requires_grad = True\n",
    "\n",
    "    for _ in range(iters):\n",
    "        outputs = model(perturbed_image)\n",
    "        loss = criterion(outputs, label)\n",
    "\n",
    "        # Compute gradients\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        gradient = perturbed_image.grad.data\n",
    "\n",
    "        # Apply small perturbation and project back into the allowed epsilon-ball\n",
    "        perturbed_image = perturbed_image + alpha * gradient.sign()\n",
    "        perturbed_image = torch.clamp(perturbed_image, image - epsilon, image + epsilon)\n",
    "        perturbed_image = torch.clamp(perturbed_image, -1, 1)  # Keep values in range\n",
    "        perturbed_image.requires_grad = True\n",
    "\n",
    "    return perturbed_image\n",
    "\n",
    "def test_pgd(model, test_loader, epsilon, alpha, iters):\n",
    "    \"\"\"\n",
    "    Evaluates the model on adversarial examples generated using PGD.\n",
    "    \"\"\"\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate adversarial example using PGD\n",
    "        adv_images = pgd_attack(images, labels, model, epsilon, alpha, iters)\n",
    "\n",
    "        # Re-classify the perturbed image\n",
    "        adv_outputs = model(adv_images)\n",
    "        _, adv_pred = torch.max(adv_outputs, 1)\n",
    "\n",
    "        # Compare predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (adv_pred == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"PGD Attack (ε={epsilon}, α={alpha}, iters={iters}) - Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Run PGD Attack\n",
    "test_pgd(model, test_loader, epsilon=0.2, alpha=0.01, iters=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def gaussian_noise_attack(image, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to the image.\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(image) * sigma\n",
    "    noisy_image = image + noise\n",
    "    noisy_image = torch.clamp(noisy_image, -1, 1)  # Keep pixel values in range\n",
    "    return noisy_image\n",
    "\n",
    "def test_gaussian_noise(model, test_loader, sigma):\n",
    "    \"\"\"\n",
    "    Evaluates the model on images with added Gaussian noise.\n",
    "    \"\"\"\n",
    "    correct, total = 0, 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Generate noisy image\n",
    "        noisy_images = gaussian_noise_attack(images, sigma)\n",
    "\n",
    "        # Re-classify the noisy image\n",
    "        outputs = model(noisy_images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Compare predictions\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Gaussian Noise (σ={sigma}) - Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "# Run Gaussian Noise Attack\n",
    "test_gaussian_noise(model, test_loader, sigma=0.1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
